{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle as pkl\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = r'C:/Users/CHICHI/Desktop/文本正则化/input'\n",
    "self_classes = [\"PLAIN\", \"PUNCT\"]\n",
    "dict_pkl_name = r'C:/Users/CHICHI/Desktop/文本正则化/output/dict.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    print('extracting start...')\n",
    "\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file))\n",
    "    train = open(os.path.join(INPUT_PATH, file), encoding='UTF8')\n",
    "    line = train.readline()\n",
    "    res = dict()\n",
    "    total = 0\n",
    "    not_same = 0\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0+1: pos]\n",
    "        if class_ not in self_classes:\n",
    "            entry_num += 1\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0] != arr[1]:\n",
    "                not_same += 1\n",
    "            if arr[0] not in res:\n",
    "                res[arr[0]] = dict()\n",
    "                res[arr[0]][arr[1]] = 1\n",
    "            else:\n",
    "                if arr[1] in res[arr[0]]:\n",
    "                    res[arr[0]][arr[1]] += 1\n",
    "                else:\n",
    "                    res[arr[0]][arr[1]] = 1\n",
    "    train.close()\n",
    "    print(file + ':\\tTotal: {}, Have diff value: {}, dict entry num: {} '.\n",
    "          format(total, not_same, entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "    for file in files:\n",
    "        print(\"extracting from file {} ...\".format(file))\n",
    "        s1 = time.time()\n",
    "        train = open(os.path.join(INPUT_PATH, file), encoding='UTF8')\n",
    "        line = train.readline()\n",
    "        while 1:\n",
    "            line = train.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            total += 1\n",
    "            pos0 = line.find('\"')\n",
    "            pos = line.find('\",\"')\n",
    "            class_ = line[pos0 + 1: pos]\n",
    "            if class_ not in self_classes:\n",
    "                entry_num += 1\n",
    "                text = line[pos + 2:]\n",
    "                if text[:3] == '\",\"':\n",
    "                    continue\n",
    "                text = text[1:-1]\n",
    "                arr = text.split('\",\"')\n",
    "                if arr[0] == '<eos>':\n",
    "                    continue\n",
    "                if arr[1] != '<self>':\n",
    "                    not_same += 1\n",
    "\n",
    "                if arr[1] == '<self>' or arr[1] == 'sil':\n",
    "                    arr[1] = arr[0]\n",
    "\n",
    "                if arr[0] not in res:\n",
    "                    res[arr[0]] = dict()\n",
    "                    res[arr[0]][arr[1]] = 1\n",
    "                else:\n",
    "                    if arr[1] in res[arr[0]]:\n",
    "                        res[arr[0]][arr[1]] += 1\n",
    "                    else:\n",
    "                        res[arr[0]][arr[1]] = 1\n",
    "        train.close()\n",
    "        print(file + ':\\tTotal: {}, Have diff value: {}, dict entry num: {} '.\n",
    "              format(total, not_same, entry_num))\n",
    "        print(\"time costs: {}\".format(time.time() - s1))\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting start...\n",
      "extracting from file en_train.csv ...\n",
      "en_train.csv:\tTotal: 9918441, Have diff value: 623321, dict entry num: 684241 \n",
      "time costs: 12.228523015975952\n",
      "extracting from file output_1.csv ...\n",
      "output_1.csv:\tTotal: 67101629, Have diff value: 4558582, dict entry num: 9063415 \n",
      "time costs: 81.61255216598511\n",
      "extracting from file output_6.csv ...\n",
      "output_6.csv:\tTotal: 124336086, Have diff value: 8493411, dict entry num: 17446970 \n",
      "time costs: 82.63766813278198\n",
      "extracting from file output_11.csv ...\n",
      "output_11.csv:\tTotal: 181494302, Have diff value: 12428910, dict entry num: 25824719 \n",
      "time costs: 82.9567813873291\n",
      "extracting from file output_16.csv ...\n",
      "output_16.csv:\tTotal: 238523401, Have diff value: 16360936, dict entry num: 34190362 \n",
      "time costs: 82.3589677810669\n",
      "extracting from file output_21.csv ...\n",
      "output_21.csv:\tTotal: 295674425, Have diff value: 20292091, dict entry num: 42564904 \n",
      "time costs: 82.90948534011841\n",
      "extracting from file output_91.csv ...\n",
      "output_91.csv:\tTotal: 352830815, Have diff value: 24225294, dict entry num: 50942242 \n",
      "time costs: 83.91496181488037\n",
      "extracting from file output_96.csv ...\n",
      "output_96.csv:\tTotal: 410013747, Have diff value: 28159273, dict entry num: 59320637 \n",
      "time costs: 84.54858422279358\n",
      "total time costs: 593.1695313453674\n"
     ]
    }
   ],
   "source": [
    "big_dict = extract()\n",
    "with open(dict_pkl_name, \"wb\") as f:\n",
    "    pkl.dump(big_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pkl_name = r'C:/Users/CHICHI/Desktop/文本正则化/output/letter_dict.pkl'\n",
    "target_class = \"LETTERS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    print('extracting start...')\n",
    "\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file_name = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file_name))\n",
    "    train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "    train.readline()\n",
    "    res = {\"LETTERS\": {}, \"PLAIN\": {}}\n",
    "    total = 0\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0+1: pos]\n",
    "        if class_ == target_class:\n",
    "            entry_num += 1\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0] in res[\"LETTERS\"]:\n",
    "                res[\"LETTERS\"][arr[0]] += 1\n",
    "            else:\n",
    "                res[\"LETTERS\"][arr[0]] = 1\n",
    "    train.close()\n",
    "    print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "          format(total, entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "    for file_name in files:\n",
    "        print(\"extracting from file {} ...\".format(file_name))\n",
    "        s1 = time.time()\n",
    "        train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "        train.readline()\n",
    "        while 1:\n",
    "            line = train.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            total += 1\n",
    "            pos0 = line.find('\"')\n",
    "            pos = line.find('\",\"')\n",
    "            class_ = line[pos0 + 1: pos]\n",
    "            if class_ == target_class:\n",
    "                entry_num += 1\n",
    "                text = line[pos + 2:]\n",
    "                if text[:3] == '\",\"':\n",
    "                    continue\n",
    "                text = text[1:-1]\n",
    "                arr = text.split('\",\"')\n",
    "                if arr[0] in res[\"LETTERS\"]:\n",
    "                    res[\"LETTERS\"][arr[0]] += 1\n",
    "                else:\n",
    "                    res[\"LETTERS\"][arr[0]] = 1\n",
    "        train.close()\n",
    "        print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "              format(total, entry_num))\n",
    "        print(\"time costs: {}\".format(time.time() - s1))\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    with open(dict_pkl_name, \"wb\") as f:\n",
    "        pkl.dump(res, f)\n",
    "    print(\"set size: \", len(res))\n",
    "    print(\"dict dumped!\")\n",
    "\n",
    "\n",
    "def double_check():\n",
    "    with open(dict_pkl_name, \"rb\") as f:\n",
    "        letter_dict = pkl.load(f)\n",
    "    print(\"set size: \", len(letter_dict[\"LETTERS\"].keys()))\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file_name = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file_name))\n",
    "    train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "    train.readline()\n",
    "    total = 0\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0 + 1: pos]\n",
    "        if class_ == \"PLAIN\":\n",
    "            entry_num += 1\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0] in letter_dict[\"LETTERS\"]:\n",
    "                if arr[0] in letter_dict[\"PLAIN\"]:\n",
    "                    letter_dict[\"PLAIN\"][arr[0]] += 1\n",
    "                else:\n",
    "                    letter_dict[\"PLAIN\"][arr[0]] = 1\n",
    "    train.close()\n",
    "    print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "          format(total, entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "    for file_name in files:\n",
    "        print(\"extracting from file {} ...\".format(file_name))\n",
    "        s1 = time.time()\n",
    "        train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "        train.readline()\n",
    "        while 1:\n",
    "            line = train.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            total += 1\n",
    "            pos0 = line.find('\"')\n",
    "            pos = line.find('\",\"')\n",
    "            class_ = line[pos0 + 1: pos]\n",
    "            if class_ == \"PLAIN\":\n",
    "                entry_num += 1\n",
    "                text = line[pos + 2:]\n",
    "                if text[:3] == '\",\"':\n",
    "                    continue\n",
    "                text = text[1:-1]\n",
    "                arr = text.split('\",\"')\n",
    "                if arr[0] in letter_dict[\"LETTERS\"]:\n",
    "                    if arr[0] in letter_dict[\"PLAIN\"]:\n",
    "                        letter_dict[\"PLAIN\"][arr[0]] += 1\n",
    "                    else:\n",
    "                        letter_dict[\"PLAIN\"][arr[0]] = 1\n",
    "        train.close()\n",
    "        print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "              format(total, entry_num))\n",
    "        print(\"time costs: {}\".format(time.time() - s1))\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    with open(dict_pkl_name, \"wb\") as f:\n",
    "        pkl.dump(letter_dict, f)\n",
    "    print(\"set size: \", len(letter_dict[\"LETTERS\"].keys()))\n",
    "    print(\"dict dumped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting start...\n",
      "extracting from file en_train.csv ...\n",
      "en_train.csv:\tTotal: 9918441, set entry num: 152795 \n",
      "time costs: 10.417058944702148\n",
      "extracting from file output_1.csv ...\n",
      "output_1.csv:\tTotal: 67101629, set entry num: 961170 \n",
      "time costs: 67.41803455352783\n",
      "extracting from file output_6.csv ...\n",
      "output_6.csv:\tTotal: 124336086, set entry num: 1771145 \n",
      "time costs: 65.05375957489014\n",
      "extracting from file output_11.csv ...\n",
      "output_11.csv:\tTotal: 181494302, set entry num: 2577522 \n",
      "time costs: 65.53348422050476\n",
      "extracting from file output_16.csv ...\n",
      "output_16.csv:\tTotal: 238523401, set entry num: 3384238 \n",
      "time costs: 66.31754994392395\n",
      "extracting from file output_21.csv ...\n",
      "output_21.csv:\tTotal: 295674425, set entry num: 4193083 \n",
      "time costs: 65.28885889053345\n",
      "extracting from file output_91.csv ...\n",
      "output_91.csv:\tTotal: 352830815, set entry num: 5002394 \n",
      "time costs: 65.88428497314453\n",
      "extracting from file output_96.csv ...\n",
      "output_96.csv:\tTotal: 410013747, set entry num: 5811716 \n",
      "time costs: 64.74295997619629\n",
      "total time costs: 470.6559910774231\n",
      "set size:  2\n",
      "dict dumped!\n",
      "set size:  227433\n",
      "extracting from file en_train.csv ...\n",
      "en_train.csv:\tTotal: 9918441, set entry num: 7353693 \n",
      "time costs: 17.41508436203003\n",
      "extracting from file output_1.csv ...\n",
      "output_1.csv:\tTotal: 67101629, set entry num: 45824225 \n",
      "time costs: 107.04745411872864\n",
      "extracting from file output_6.csv ...\n",
      "output_6.csv:\tTotal: 124336086, set entry num: 84327650 \n",
      "time costs: 106.95627474784851\n",
      "extracting from file output_11.csv ...\n",
      "output_11.csv:\tTotal: 181494302, set entry num: 122782736 \n",
      "time costs: 107.25358557701111\n",
      "extracting from file output_16.csv ...\n",
      "output_16.csv:\tTotal: 238523401, set entry num: 161142250 \n",
      "time costs: 110.04490256309509\n",
      "extracting from file output_21.csv ...\n",
      "output_21.csv:\tTotal: 295674425, set entry num: 199588104 \n",
      "time costs: 112.16664624214172\n",
      "extracting from file output_91.csv ...\n",
      "output_91.csv:\tTotal: 352830815, set entry num: 238042610 \n",
      "time costs: 112.31774830818176\n",
      "extracting from file output_96.csv ...\n",
      "output_96.csv:\tTotal: 410013747, set entry num: 276515109 \n",
      "time costs: 115.19503116607666\n",
      "total time costs: 788.3977313041687\n",
      "set size:  227433\n",
      "dict dumped!\n"
     ]
    }
   ],
   "source": [
    "extract()\n",
    "double_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_pkl_name = r'C:/Users/CHICHI/Desktop/文本正则化/output/letter_set.pkl'\n",
    "target_class = \"LETTERS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    print('extracting start...')\n",
    "\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file_name = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file_name))\n",
    "    train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "    train.readline()\n",
    "    res = set()\n",
    "    total = 0\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0+1: pos]\n",
    "        if class_ == target_class:\n",
    "            entry_num += 1\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            res.add(arr[0])\n",
    "    train.close()\n",
    "    print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "          format(total, entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "    for file_name in files:\n",
    "        print(\"extracting from file {} ...\".format(file_name))\n",
    "        s1 = time.time()\n",
    "        train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "        train.readline()\n",
    "        while 1:\n",
    "            line = train.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            total += 1\n",
    "            pos0 = line.find('\"')\n",
    "            pos = line.find('\",\"')\n",
    "            class_ = line[pos0 + 1: pos]\n",
    "            if class_ == target_class:\n",
    "                entry_num += 1\n",
    "                text = line[pos + 2:]\n",
    "                if text[:3] == '\",\"':\n",
    "                    continue\n",
    "                text = text[1:-1]\n",
    "                arr = text.split('\",\"')\n",
    "                res.add(arr[0])\n",
    "        train.close()\n",
    "        print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "              format(total, entry_num))\n",
    "        print(\"time costs: {}\".format(time.time() - s1))\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    with open(set_pkl_name, \"wb\") as f:\n",
    "        pkl.dump(res, f)\n",
    "    print(\"set size: \", len(res))\n",
    "    print(\"dict dumped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_check():\n",
    "    with open(set_pkl_name, \"rb\") as f:\n",
    "        letter_set = pkl.load(f)\n",
    "    print(\"set size: \", len(letter_set))\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file_name = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file_name))\n",
    "    train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "    train.readline()\n",
    "    total = 0\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0 + 1: pos]\n",
    "        if class_ == \"PLAIN\":\n",
    "            entry_num += 1\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0] in letter_set:\n",
    "                letter_set.remove(arr[0])\n",
    "    train.close()\n",
    "    print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "          format(total, entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "    for file_name in files:\n",
    "        print(\"extracting from file {} ...\".format(file_name))\n",
    "        s1 = time.time()\n",
    "        train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "        train.readline()\n",
    "        while 1:\n",
    "            line = train.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            total += 1\n",
    "            pos0 = line.find('\"')\n",
    "            pos = line.find('\",\"')\n",
    "            class_ = line[pos0 + 1: pos]\n",
    "            if class_ == \"PLAIN\":\n",
    "                entry_num += 1\n",
    "                text = line[pos + 2:]\n",
    "                if text[:3] == '\",\"':\n",
    "                    continue\n",
    "                text = text[1:-1]\n",
    "                arr = text.split('\",\"')\n",
    "                if arr[0] in letter_set:\n",
    "                    letter_set.remove(arr[0])\n",
    "        train.close()\n",
    "        print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "              format(total, entry_num))\n",
    "        print(\"time costs: {}\".format(time.time() - s1))\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    with open(set_pkl_name, \"wb\") as f:\n",
    "        pkl.dump(letter_set, f)\n",
    "    print(\"set size: \", len(letter_set))\n",
    "    print(\"dict dumped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting start...\n",
      "extracting from file en_train.csv ...\n",
      "en_train.csv:\tTotal: 9918441, set entry num: 152795 \n",
      "time costs: 10.365192890167236\n",
      "extracting from file output_1.csv ...\n",
      "output_1.csv:\tTotal: 67101629, set entry num: 961170 \n",
      "time costs: 67.135586977005\n",
      "extracting from file output_6.csv ...\n",
      "output_6.csv:\tTotal: 124336086, set entry num: 1771145 \n",
      "time costs: 66.64194893836975\n",
      "extracting from file output_11.csv ...\n",
      "output_11.csv:\tTotal: 181494302, set entry num: 2577522 \n",
      "time costs: 66.47791457176208\n",
      "extracting from file output_16.csv ...\n",
      "output_16.csv:\tTotal: 238523401, set entry num: 3384238 \n",
      "time costs: 66.4736590385437\n",
      "extracting from file output_21.csv ...\n",
      "output_21.csv:\tTotal: 295674425, set entry num: 4193083 \n",
      "time costs: 67.86413741111755\n",
      "extracting from file output_91.csv ...\n",
      "output_91.csv:\tTotal: 352830815, set entry num: 5002394 \n",
      "time costs: 64.60347294807434\n",
      "extracting from file output_96.csv ...\n",
      "output_96.csv:\tTotal: 410013747, set entry num: 5811716 \n",
      "time costs: 68.16697549819946\n",
      "total time costs: 477.7299180030823\n",
      "set size:  227433\n",
      "dict dumped!\n",
      "set size:  227433\n",
      "extracting from file en_train.csv ...\n",
      "en_train.csv:\tTotal: 9918441, set entry num: 7353693 \n",
      "time costs: 17.981709718704224\n",
      "extracting from file output_1.csv ...\n",
      "output_1.csv:\tTotal: 67101629, set entry num: 45824225 \n",
      "time costs: 109.05768775939941\n",
      "extracting from file output_6.csv ...\n",
      "output_6.csv:\tTotal: 124336086, set entry num: 84327650 \n",
      "time costs: 108.16807723045349\n",
      "extracting from file output_11.csv ...\n",
      "output_11.csv:\tTotal: 181494302, set entry num: 122782736 \n",
      "time costs: 114.91918087005615\n",
      "extracting from file output_16.csv ...\n",
      "output_16.csv:\tTotal: 238523401, set entry num: 161142250 \n",
      "time costs: 109.71318769454956\n",
      "extracting from file output_21.csv ...\n",
      "output_21.csv:\tTotal: 295674425, set entry num: 199588104 \n",
      "time costs: 110.27286028862\n",
      "extracting from file output_91.csv ...\n",
      "output_91.csv:\tTotal: 352830815, set entry num: 238042610 \n",
      "time costs: 109.338383436203\n",
      "extracting from file output_96.csv ...\n",
      "output_96.csv:\tTotal: 410013747, set entry num: 276515109 \n",
      "time costs: 109.3219358921051\n",
      "total time costs: 788.7750267982483\n",
      "set size:  224397\n",
      "dict dumped!\n"
     ]
    }
   ],
   "source": [
    "extract()\n",
    "double_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pkl_name = r'C:/Users/CHICHI/Desktop/文本正则化/output/plain_dict.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    print('extracting start...')\n",
    "\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file))\n",
    "    train = open(os.path.join(INPUT_PATH, file), encoding='UTF8')\n",
    "    line = train.readline()\n",
    "    res = dict()\n",
    "    total = 0\n",
    "    not_same = 0\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0+1: pos]\n",
    "        if class_ == \"PLAIN\":\n",
    "            entry_num += 1\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0] != arr[1]:\n",
    "                not_same += 1\n",
    "                if arr[0] not in res:\n",
    "                    res[arr[0]] = dict()\n",
    "                    res[arr[0]][arr[1]] = 1\n",
    "                else:\n",
    "                    if arr[1] in res[arr[0]]:\n",
    "                        res[arr[0]][arr[1]] += 1\n",
    "                    else:\n",
    "                        res[arr[0]][arr[1]] = 1\n",
    "    train.close()\n",
    "    print(file + ':\\tTotal: {}, Have diff value: {}, dict entry num: {} '.\n",
    "          format(total, not_same, entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "    for file in files:\n",
    "        print(\"extracting from file {} ...\".format(file))\n",
    "        s1 = time.time()\n",
    "        train = open(os.path.join(INPUT_PATH, file), encoding='UTF8')\n",
    "        line = train.readline()\n",
    "        while 1:\n",
    "            line = train.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            total += 1\n",
    "            pos0 = line.find('\"')\n",
    "            pos = line.find('\",\"')\n",
    "            class_ = line[pos0 + 1: pos]\n",
    "            if class_ == \"PLAIN\":\n",
    "                entry_num += 1\n",
    "                text = line[pos + 2:]\n",
    "                if text[:3] == '\",\"':\n",
    "                    continue\n",
    "                text = text[1:-1]\n",
    "                arr = text.split('\",\"')\n",
    "                if arr[0] == '<eos>':\n",
    "                    continue\n",
    "                if arr[1] != '<self>':\n",
    "                    not_same += 1\n",
    "                    if arr[0] not in res:\n",
    "                        res[arr[0]] = dict()\n",
    "                        res[arr[0]][arr[1]] = 1\n",
    "                    else:\n",
    "                        if arr[1] in res[arr[0]]:\n",
    "                            res[arr[0]][arr[1]] += 1\n",
    "                        else:\n",
    "                            res[arr[0]][arr[1]] = 1\n",
    "        train.close()\n",
    "        print(file + ':\\tTotal: {}, Have diff value: {}, dict entry num: {} '.\n",
    "              format(total, not_same, entry_num))\n",
    "        print(\"time costs: {}\".format(time.time() - s1))\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    with open(dict_pkl_name, \"wb\") as f:\n",
    "        pkl.dump(res, f)\n",
    "    print(\"dict dumped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_check():\n",
    "    print(\"loading first dict ...\")\n",
    "    with open(dict_pkl_name, \"rb\") as f:\n",
    "        res = pkl.load(f)\n",
    "\n",
    "    print('double check start...')\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file))\n",
    "    train = open(os.path.join(INPUT_PATH, file), encoding='UTF8')\n",
    "    line = train.readline()\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0 + 1: pos]\n",
    "        if class_ == \"PLAIN\":\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0] in res and arr[0] == arr[1]:\n",
    "                entry_num += 1\n",
    "                if arr[0] in res[arr[0]]:\n",
    "                    res[arr[0]][arr[0]] += 1\n",
    "                else:\n",
    "                    res[arr[0]][arr[0]] = 1\n",
    "    train.close()\n",
    "    print(\"double check add {} entries\".format(entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "    for file in files:\n",
    "        print(\"extracting from file {} ...\".format(file))\n",
    "        s1 = time.time()\n",
    "        train = open(os.path.join(INPUT_PATH, file), encoding='UTF8')\n",
    "        line = train.readline()\n",
    "        while 1:\n",
    "            line = train.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            pos0 = line.find('\"')\n",
    "            pos = line.find('\",\"')\n",
    "            class_ = line[pos0 + 1: pos]\n",
    "            if class_ == \"PLAIN\":\n",
    "                text = line[pos + 2:]\n",
    "                if text[:3] == '\",\"':\n",
    "                    continue\n",
    "                text = text[1:-1]\n",
    "                arr = text.split('\",\"')\n",
    "                if arr[0] == '<eos>':\n",
    "                    continue\n",
    "                if arr[0] in res and arr[1] == '<self>':\n",
    "                    entry_num += 1\n",
    "                    if arr[0] in res[arr[0]]:\n",
    "                        res[arr[0]][arr[0]] += 1\n",
    "                    else:\n",
    "                        res[arr[0]][arr[0]] = 1\n",
    "        train.close()\n",
    "\n",
    "        print(\"time costs: {}\".format(time.time() - s1))\n",
    "    print(\"double check add {} entries\".format(entry_num))\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    with open(dict_pkl_name, \"wb\") as f:\n",
    "        pkl.dump(res, f)\n",
    "    print(\"dict dumped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting start...\n",
      "extracting from file en_train.csv ...\n",
      "en_train.csv:\tTotal: 9918441, Have diff value: 36472, dict entry num: 7353693 \n",
      "time costs: 16.32365107536316\n",
      "extracting from file output_1.csv ...\n",
      "output_1.csv:\tTotal: 67101629, Have diff value: 226877, dict entry num: 45824225 \n",
      "time costs: 104.18785500526428\n",
      "extracting from file output_6.csv ...\n",
      "output_6.csv:\tTotal: 124336086, Have diff value: 417304, dict entry num: 84327650 \n",
      "time costs: 105.57754302024841\n",
      "extracting from file output_11.csv ...\n",
      "output_11.csv:\tTotal: 181494302, Have diff value: 607241, dict entry num: 122782736 \n",
      "time costs: 104.00359034538269\n",
      "extracting from file output_16.csv ...\n",
      "output_16.csv:\tTotal: 238523401, Have diff value: 796740, dict entry num: 161142250 \n",
      "time costs: 109.60823726654053\n",
      "extracting from file output_21.csv ...\n",
      "output_21.csv:\tTotal: 295674425, Have diff value: 986895, dict entry num: 199588104 \n",
      "time costs: 105.47260069847107\n",
      "extracting from file output_91.csv ...\n",
      "output_91.csv:\tTotal: 352830815, Have diff value: 1176605, dict entry num: 238042610 \n",
      "time costs: 102.39688110351562\n",
      "extracting from file output_96.csv ...\n",
      "output_96.csv:\tTotal: 410013747, Have diff value: 1367074, dict entry num: 276515109 \n",
      "time costs: 97.13436484336853\n",
      "total time costs: 744.7057282924652\n",
      "dict dumped!\n",
      "loading first dict ...\n",
      "double check start...\n",
      "extracting from file en_train.csv ...\n",
      "double check add 15676 entries\n",
      "time costs: 14.359775304794312\n",
      "extracting from file output_1.csv ...\n",
      "time costs: 93.00074458122253\n",
      "extracting from file output_6.csv ...\n",
      "time costs: 93.43649506568909\n",
      "extracting from file output_11.csv ...\n",
      "time costs: 93.54343366622925\n",
      "extracting from file output_16.csv ...\n",
      "time costs: 94.73276448249817\n",
      "extracting from file output_21.csv ...\n",
      "time costs: 94.15708374977112\n",
      "extracting from file output_91.csv ...\n",
      "time costs: 94.65577864646912\n",
      "extracting from file output_96.csv ...\n",
      "time costs: 94.82769751548767\n",
      "double check add 590742 entries\n",
      "total time costs: 672.717791557312\n",
      "dict dumped!\n"
     ]
    }
   ],
   "source": [
    "extract()\n",
    "double_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pkl_name = r'C:/Users/CHICHI/Desktop/文本正则化/output/verbatim_dict.pkl'\n",
    "target_class = \"VERBATIM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    print('extracting start...')\n",
    "\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file))\n",
    "    train = open(os.path.join(INPUT_PATH, file), encoding='UTF8')\n",
    "    line = train.readline()\n",
    "    res = dict()\n",
    "    total = 0\n",
    "    not_same = 0\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0+1: pos]\n",
    "        if class_ == target_class:\n",
    "            entry_num += 1\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0] != arr[1]:\n",
    "                not_same += 1\n",
    "                if arr[0] not in res:\n",
    "                    res[arr[0]] = dict()\n",
    "                    res[arr[0]][arr[1]] = 1\n",
    "                else:\n",
    "                    if arr[1] in res[arr[0]]:\n",
    "                        res[arr[0]][arr[1]] += 1\n",
    "                    else:\n",
    "                        res[arr[0]][arr[1]] = 1\n",
    "    train.close()\n",
    "    print(file + ':\\tTotal: {}, Have diff value: {}, dict entry num: {} '.\n",
    "          format(total, not_same, entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting start...\n",
      "extracting from file en_train.csv ...\n",
      "en_train.csv:\tTotal: 9918441, Have diff value: 25837, dict entry num: 78108 \n",
      "time costs: 10.04526138305664\n",
      "total time costs: 10.04526138305664\n"
     ]
    }
   ],
   "source": [
    "big_dict = extract()\n",
    "with open(dict_pkl_name, \"wb\") as f:\n",
    "    pkl.dump(big_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pkl_name = r'C:/Users/CHICHI/Desktop/文本正则化/output/year_dict_big.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_year(token):\n",
    "    return token.isdigit() and 2 <= len(token) <= 4 and int(token) <= 3000\n",
    "\n",
    "\n",
    "def extract():\n",
    "    print('extracting start...')\n",
    "\n",
    "    # Work with primary dataset\n",
    "    s = time.time()\n",
    "    file_name = \"en_train.csv\"\n",
    "    print(\"extracting from file {} ...\".format(file_name))\n",
    "    train = open(os.path.join(INPUT_PATH, file_name), encoding='UTF8')\n",
    "    train.readline()\n",
    "    res = {}\n",
    "    total = 0\n",
    "    entry_num = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos0 = line.find('\"')\n",
    "        pos = line.find('\",\"')\n",
    "        class_ = line[pos0+1: pos]\n",
    "        text = line[pos + 2:]\n",
    "        if text[:3] == '\",\"':\n",
    "            continue\n",
    "        text = text[1:-1]\n",
    "        arr = text.split('\",\"')\n",
    "        if is_year(arr[0]):\n",
    "            entry_num += 1\n",
    "            if arr[0] not in res:\n",
    "                res[arr[0]] = {}\n",
    "            if class_ not in res[arr[0]]:\n",
    "                res[arr[0]][class_] = 1\n",
    "            else:\n",
    "                res[arr[0]][class_] += 1\n",
    "\n",
    "    train.close()\n",
    "    print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "          format(total, entry_num))\n",
    "    print(\"time costs: {}\".format(time.time() - s))\n",
    "\n",
    "    # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "    files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "             'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "    for file_name in files:\n",
    "        print(\"extracting from file {} ...\".format(file_name))\n",
    "        s1 = time.time()\n",
    "        train = open(os.path.join(INPUT_PATH,file_name), encoding='UTF8')\n",
    "        train.readline()\n",
    "        while 1:\n",
    "            line = train.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            total += 1\n",
    "            pos0 = line.find('\"')\n",
    "            pos = line.find('\",\"')\n",
    "            class_ = line[pos0 + 1: pos]\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if is_year(arr[0]):\n",
    "                entry_num += 1\n",
    "                if arr[0] not in res:\n",
    "                    res[arr[0]] = {}\n",
    "                if class_ not in res[arr[0]]:\n",
    "                    res[arr[0]][class_] = 1\n",
    "                else:\n",
    "                    res[arr[0]][class_] += 1\n",
    "        train.close()\n",
    "        print(file_name + ':\\tTotal: {}, set entry num: {} '.\n",
    "              format(total, entry_num))\n",
    "        print(\"time costs: {}\".format(time.time() - s1))\n",
    "    print(\"total time costs: {}\".format(time.time() - s))\n",
    "    with open(dict_pkl_name, \"wb\") as f:\n",
    "        pkl.dump(res, f)\n",
    "    print(\"set size: \", len(res))\n",
    "    print(\"dict dumped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting start...\n",
      "extracting from file en_train.csv ...\n",
      "en_train.csv:\tTotal: 9918441, set entry num: 231359 \n",
      "time costs: 17.544018745422363\n",
      "extracting from file output_1.csv ...\n",
      "output_1.csv:\tTotal: 67101629, set entry num: 1434040 \n",
      "time costs: 107.9376015663147\n",
      "extracting from file output_6.csv ...\n",
      "output_6.csv:\tTotal: 124336086, set entry num: 2638676 \n",
      "time costs: 108.5898323059082\n",
      "extracting from file output_11.csv ...\n",
      "output_11.csv:\tTotal: 181494302, set entry num: 3839502 \n",
      "time costs: 108.10953378677368\n",
      "extracting from file output_16.csv ...\n",
      "output_16.csv:\tTotal: 238523401, set entry num: 5036581 \n",
      "time costs: 109.88009262084961\n",
      "extracting from file output_21.csv ...\n",
      "output_21.csv:\tTotal: 295674425, set entry num: 6238122 \n",
      "time costs: 112.19575309753418\n",
      "extracting from file output_91.csv ...\n",
      "output_91.csv:\tTotal: 352830815, set entry num: 7438681 \n",
      "time costs: 118.83894920349121\n",
      "extracting from file output_96.csv ...\n",
      "output_96.csv:\tTotal: 410013747, set entry num: 8642556 \n",
      "time costs: 114.84523558616638\n",
      "total time costs: 797.9410169124603\n",
      "set size:  3983\n",
      "dict dumped!\n"
     ]
    }
   ],
   "source": [
    "extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import operator\n",
    "from num2words import num2words  # 这个包不支持中文\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"C:/Users/CHICHI/Desktop/文本正则化/input/\"\n",
    "train_file_name =  \"C:/Users/CHICHI/Desktop/文本正则化/input/en_train.csv\"\n",
    "test_file = 'C:/Users/CHICHI/Desktop/文本正则化/input/en_test_2.csv'\n",
    "baseline_file = 'C:/Users/CHICHI/Desktop/文本正则化/output/submission_1.csv'\n",
    "pkl_name = \"C:/Users/CHICHI/Desktop/文本正则化/output/class_dict.pkl\"\n",
    "train_df = pd.read_csv(train_file_name)\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = str.maketrans(\"₀₁₂₃₄₅₆₇₈₉\", \"0123456789\")\n",
    "SUP = str.maketrans(\"⁰¹²³⁴⁵⁶⁷⁸⁹\", \"0123456789\")\n",
    "OTH = str.maketrans(\"፬\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    print('Train start...')\n",
    "    if os.path.exists(pkl_name):\n",
    "        with open(pkl_name, \"rb\") as f:\n",
    "            res = pkl.load(f)\n",
    "    else:\n",
    "        # Work with primary dataset\n",
    "        train_file = open(train_file_name, encoding='UTF8')\n",
    "        train_file.readline()\n",
    "        res = dict()\n",
    "        total = 0\n",
    "        not_same = 0\n",
    "        while 1:\n",
    "            line = train_file.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            total += 1\n",
    "            pos = line.find('\",\"')\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0] != arr[1]:\n",
    "                not_same += 1\n",
    "            if arr[0] not in res:\n",
    "                res[arr[0]] = dict()\n",
    "                res[arr[0]][arr[1]] = 1\n",
    "            else:\n",
    "                if arr[1] in res[arr[0]]:\n",
    "                    res[arr[0]][arr[1]] += 1\n",
    "                else:\n",
    "                    res[arr[0]][arr[1]] = 1\n",
    "        train_file.close()\n",
    "        print(train_file_name + ':\\tTotal: {} Have diff value: {}'.format(total, not_same))\n",
    "\n",
    "        # Work with additional dataset from https://www.kaggle.com/google-nlu/text-normalization\n",
    "        files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv', \\\n",
    "                 'output_21.csv', 'output_91.csv', 'output_96.csv']\n",
    "\n",
    "        for add_file_name in files:\n",
    "            train_file = open( INPUT_PATH+add_file_name, encoding='UTF8')\n",
    "            train_file.readline()\n",
    "            while 1:\n",
    "                line = train_file.readline().strip()\n",
    "                if line == '':\n",
    "                    break\n",
    "                line = line.replace(',NA,', ',\"NA\",')\n",
    "                total += 1\n",
    "                pos = line.find('\",\"')\n",
    "                text = line[pos + 2:]\n",
    "                if text[:3] == '\",\"':\n",
    "                    continue\n",
    "                text = text[1:-1]\n",
    "                arr = text.split('\",\"')\n",
    "                if arr[0] == '<eos>':\n",
    "                    continue\n",
    "                if arr[1] != '<self>':\n",
    "                    not_same += 1\n",
    "\n",
    "                if arr[1] == '<self>' or arr[1] == 'sil':\n",
    "                    arr[1] = arr[0]\n",
    "\n",
    "                if arr[0] not in res:\n",
    "                    res[arr[0]] = dict()\n",
    "                    res[arr[0]][arr[1]] = 1\n",
    "                else:\n",
    "                    if arr[1] in res[arr[0]]:\n",
    "                        res[arr[0]][arr[1]] += 1\n",
    "                    else:\n",
    "                        res[arr[0]][arr[1]] = 1\n",
    "            train_file.close()\n",
    "            print(add_file_name + ':\\tTotal: {} Have diff value: {}'.format(total, not_same))\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(res):\n",
    "    sdict = {}\n",
    "    sdict['km2'] = 'square kilometers'\n",
    "    sdict['km'] = 'kilometers'\n",
    "    sdict['kg'] = 'kilograms'\n",
    "    sdict['lb'] = 'pounds'\n",
    "    sdict['dr'] = 'doctor'\n",
    "    sdict['m²'] = 'square meters'\n",
    "\n",
    "    total = 0\n",
    "    changes = 0\n",
    "    out = open(baseline_file, \"w\", encoding='UTF8')\n",
    "    out.write('\"id\",\"after\"\\n')\n",
    "    test = open(test_file, encoding='UTF8')\n",
    "    test.readline().strip()\n",
    "    while 1:\n",
    "        line = test.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "\n",
    "        pos = line.find(',')\n",
    "        i1 = line[:pos]\n",
    "        line = line[pos + 1:]\n",
    "\n",
    "        pos = line.find(',')\n",
    "        i2 = line[:pos]\n",
    "        line = line[pos + 1:]\n",
    "\n",
    "        line = line[1:-1]\n",
    "        out.write('\"' + i1 + '_' + i2 + '\",')\n",
    "        if line in res:\n",
    "            srtd = sorted(res[line].items(), key=operator.itemgetter(1), reverse=True)\n",
    "            out.write('\"' + srtd[0][0] + '\"')\n",
    "            changes += 1\n",
    "        else:\n",
    "            # line.split(' ')\n",
    "            if len(line) > 1:\n",
    "                val = line.split(',')\n",
    "                if len(val) == 2 and val[0].isdigit and val[1].isdigit:\n",
    "                    line = ''.join(val)\n",
    "\n",
    "            if line.isdigit():\n",
    "                srtd = line.translate(SUB)\n",
    "                srtd = srtd.translate(SUP)\n",
    "                srtd = srtd.translate(OTH)\n",
    "                out.write('\"' + num2words(float(srtd)) + '\"')\n",
    "                changes += 1\n",
    "            elif len(line.split(' ')) > 1:\n",
    "                val = line.split(' ')\n",
    "                for i, v in enumerate(val):\n",
    "                    if v.isdigit():\n",
    "                        srtd = v.translate(SUB)\n",
    "                        srtd = srtd.translate(SUP)\n",
    "                        srtd = srtd.translate(OTH)\n",
    "                        val[i] = num2words(float(srtd))\n",
    "                    elif v in sdict:\n",
    "                        val[i] = sdict[v]\n",
    "\n",
    "                out.write('\"' + ' '.join(val) + '\"')\n",
    "                changes += 1\n",
    "            else:\n",
    "                out.write('\"' + line + '\"')\n",
    "\n",
    "        out.write('\\n')\n",
    "        total += 1\n",
    "\n",
    "    print('Total: {} Changed: {}'.format(total, changes))\n",
    "    test.close()\n",
    "    out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train start...\n",
      "C:/Users/CHICHI/Desktop/文本正则化/input/en_train.csv:\tTotal: 9918441 Have diff value: 659793\n",
      "output_1.csv:\tTotal: 67101629 Have diff value: 12723310\n",
      "output_6.csv:\tTotal: 124336086 Have diff value: 24795377\n",
      "output_11.csv:\tTotal: 181494302 Have diff value: 36848944\n",
      "output_16.csv:\tTotal: 238523401 Have diff value: 48886815\n",
      "output_21.csv:\tTotal: 295674425 Have diff value: 60943615\n",
      "output_91.csv:\tTotal: 352830815 Have diff value: 72996182\n",
      "output_96.csv:\tTotal: 410013747 Have diff value: 85056247\n",
      "Total: 956046 Changed: 897170\n"
     ]
    }
   ],
   "source": [
    "res = train()\n",
    "solve(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbatim(x):\n",
    "    #this appears to be mainly deals with symbols that will be in the trained dictionary. \n",
    "    #only other thing is letters we need to separate\n",
    "    if len(x)>1:\n",
    "        x_list = [i for i in x]\n",
    "        return \" \".join(x_list)\n",
    "    else:\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time(x):\n",
    "    x = re.sub('\\.','',x)\n",
    "    if len(x.split(':')) == 2:\n",
    "        x = re.sub(':',' ',x)\n",
    "        x = re.sub('([^0-9])', r' \\1 ', x)\n",
    "        x = re.sub('\\s{2,}', ' ', x)\n",
    "        time_list = x.split(' ')\n",
    "        t_list = [i for i in time_list if i != \"\"] \n",
    "        for i,v in enumerate(t_list):\n",
    "            if v == '00':\n",
    "                t_list[i] = ''\n",
    "            elif v.isdigit():\n",
    "                t_list[i] = num2words(int(v))\n",
    "            else:\n",
    "                t_list[i] = v.lower()\n",
    "        t = \" \".join(t_list)\n",
    "    elif len(x.split(':')) == 3:\n",
    "        x_list = x.split(':')\n",
    "        time_list = [num2words(int(num)) for num in x_list]\n",
    "        time_units = []\n",
    "        if int(x_list[0]) != 1:\n",
    "            time_units.append('hours')\n",
    "        else:\n",
    "            time_units.append('hour')\n",
    "        if int(x_list[1]) != 1:\n",
    "            time_units.append('minutes')\n",
    "        else:\n",
    "            time_units.append('minute')\n",
    "        if int(x_list[2]) != 1:\n",
    "            time_units.append('seconds')\n",
    "        else:\n",
    "            time_units.append('second')\n",
    "        t_list = [time_list[0],time_units[0],time_list[1],time_units[1],time_list[2],time_units[2]]\n",
    "        t = \" \".join(t_list)\n",
    "    else:\n",
    "        x = re.sub('([^0-9])', r' \\1 ', x)\n",
    "        x = re.sub('\\s{2,}', ' ', x)\n",
    "        time_list = x.split(' ')\n",
    "        t_list = [i for i in time_list if i != \"\"] \n",
    "        for i,v in enumerate(t_list):\n",
    "            if v == '00':\n",
    "                t_list[i] = ''\n",
    "            elif v.isdigit():\n",
    "                t_list[i] = num2words(int(v))\n",
    "            else:\n",
    "                t_list[i] = v.lower()\n",
    "        t = \" \".join(t_list)       \n",
    "        \n",
    "    time = re.sub(',',\"\",t)\n",
    "    time_final = re.sub('-',\" \",time)\n",
    "    return(time_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(x):\n",
    "    x = re.sub(',','',x)\n",
    "    sdict = {}\n",
    "    sdict['km2'] = 'square kilometers'\n",
    "    sdict['km'] = 'kilometers'\n",
    "    sdict['kg'] = 'kilograms'\n",
    "    sdict['lb'] = 'pounds'\n",
    "    sdict['dr'] = 'doctor'\n",
    "    sdict['sq'] = 'square'\n",
    "    sdict['m²'] = 'square meters'\n",
    "    sdict['in'] = 'inch'\n",
    "    sdict['oz'] = 'ounce'\n",
    "    sdict['gal'] = 'gallon'\n",
    "    sdict['m'] = 'meter'\n",
    "    sdict['m2'] = 'square meters'\n",
    "    sdict['m3'] = 'cubic meters'\n",
    "    sdict['mm'] = 'millimeters'\n",
    "    sdict['ft'] = 'feet'\n",
    "    sdict['mi'] = 'miles'\n",
    "    sdict['ha'] = \"hectare\"\n",
    "    sdict['mph'] = \"miles per hour\"\n",
    "    sdict['%'] = 'percent'\n",
    "    sdict['GB'] = 'gigabyte'\n",
    "    sdict['MB'] = 'megabyte'\n",
    "    SUB = {ord(c): ord(t) for c, t in zip(u\"₀₁₂₃₄₅₆₇₈₉\", u\"0123456789\")}\n",
    "    SUP = {ord(c): ord(t) for c, t in zip(u\"⁰¹²³⁴⁵⁶⁷⁸⁹\", u\"0123456789\")}\n",
    "    OTH = {ord(c): ord(t) for c, t in zip(u\"፬\", u\"4\")}\n",
    "\n",
    "    x = x.translate(SUB)\n",
    "    x = x.translate(SUP)\n",
    "    x = x.translate(OTH)\n",
    "    \n",
    "    if len(x.split(' ')) > 1:\n",
    "        m_list = x.split(' ')\n",
    "    elif \"/\" in x:\n",
    "        m_list = x.split('/')\n",
    "        m_list.insert(1,'per')\n",
    "    else:\n",
    "        x = re.sub('([^0-9\\.])', r' \\1 ', x)\n",
    "        x = re.sub('\\s{2,}', ' ', x)\n",
    "        measure_list = x.split(' ')\n",
    "        measure_list = [i for i in measure_list if i != \"\"]\n",
    "        m_list = [measure_list[0],\"\".join(measure_list[1:])]\n",
    "    for i,v in enumerate(m_list):\n",
    "        if v.isdigit():\n",
    "            srtd = v.translate(SUB)\n",
    "            srtd = srtd.translate(SUP)\n",
    "            srtd = srtd.translate(OTH)\n",
    "            m_list[i] = num2words(float(srtd))\n",
    "        elif is_float(v):\n",
    "            m_list[i] = decimal(v)\n",
    "        elif v in sdict:\n",
    "            m_list[i] = sdict[v]\n",
    "    measure = \" \".join(m_list)\n",
    "    measure = re.sub(',',\"\",measure)\n",
    "    measure_final = re.sub('-',\" \",measure)\n",
    "    return(measure_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal(x):\n",
    "    x = re.sub(',','',x)\n",
    "    deci_list = x.split('.')\n",
    "    deci_list.insert(1,'point')\n",
    "    if deci_list[0] ==\"\":\n",
    "        deci_list = deci_list[1:]\n",
    "    else:\n",
    "        deci_list[0] = num2words(int(deci_list[0]))\n",
    "    #dealing with decimals after . (ex: .91 = point nine one)\n",
    "    decimals_list = [num2words(int(num)) for num in deci_list[-1]]\n",
    "    decimals = \" \".join(decimals_list)\n",
    "    decimals = re.sub('zero','o',decimals)\n",
    "    deci_list[-1] = decimals\n",
    "    return(\" \".join(deci_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year(x):\n",
    "    year_list = [num for num in str(x)]\n",
    "    if len(year_list)==4 and (year_list[0] == \"1\" or (year_list[0] == \"2\" and year_list[2]!='0')):\n",
    "        year_list.insert(2, \" \")\n",
    "        year = \"\".join(year_list)\n",
    "        year = year.split(' ')\n",
    "        year = [num2words(int(num)) for num in year]\n",
    "        year = \" \".join(year)\n",
    "    elif len(year_list)==4 and (year_list[0] == \"1\" or (year_list[0] == \"2\" and year_list[2]=='0')):\n",
    "        year = \"\".join(year_list)\n",
    "        year = num2words(int(year))\n",
    "    elif  len(year_list)==2 and year_list[0]=='9':\n",
    "        new_year_list = [\"nineteen\"]\n",
    "        new_year_list.append(\"\".join(year_list))\n",
    "        new_year_list[1] = num2words(int(new_year_list[1]))\n",
    "        year = \" \".join(new_year_list)        \n",
    "    elif len(year_list)==2 and year_list[0]!='0':\n",
    "        new_year_list = [\"twenty\"]\n",
    "        new_year_list.append(\"\".join(year_list))\n",
    "        new_year_list[1] = num2words(int(new_year_list[1]))\n",
    "        year = \" \".join(new_year_list)\n",
    "    elif len(year_list)==2 and year_list[0]=='0':\n",
    "        new_year_list = ['o']\n",
    "        num = num2words(int(year_list[1]))\n",
    "        new_year_list.append(num)\n",
    "        year = \" \".join(new_year_list)\n",
    "    year = re.sub(',',\"\",year)\n",
    "    year_final = re.sub('-',\" \",year)\n",
    "    return(year_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(x):\n",
    "    x = re.sub(',','',x)\n",
    "    months = [\"january\",\"febuary\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\"]\n",
    "    \n",
    "    day = {\"01\":'first', \"02\":\"second\" , \"03\":'third', \"04\":'fourth', \"05\":'fifth', \"06\":'sixth', \"07\":'seventh', \"08\":'eighth', \"09\":'ninth', \"10\":'tenth', \"11\":'eleventh',\n",
    "    \"12\":'twelfth', \"13\":'thirteenth', \"14\":'fourteenth', \"15\":'fifteenth', \"16\":'sixteenth', \"17\":'seventeenth', \"18\":'eighteenth', \"19\":'nineteenth', \"20\":'twentieth', \"21\":'twenty-first',\n",
    "    \"22\":'twenty-second', \"23\":'twenty-third', \"24\":'twenty-fourth', \"25\":'twenty-fifth', \"26\":'twenty-sixth', \"27\":'twenty-seventh', \"28\":'twenty-eighth', \"29\":'twenty-ninth', \"30\":'thirtieth', \"31\":'thirty-first',\"1\":'first', \"2\":\"second\" , \"3\":'third', \"4\":'fourth', \"5\":'fifth', \"6\":'sixth', \"7\":'seventh', \"8\":'eighth', \"9\":'ninth'}\n",
    "\n",
    "    month = {\"01\":\"January\",\"02\":\"February\",\"03\":\"March\",\"04\":\"April\",\"05\":\"May\",\"06\":\"June\",\n",
    "         \"07\":\"July\", \"08\":\"August\",\"09\":\"September\",\"1\":\"January\",\"2\":\"February\",\"3\":\"March\",\"4\":\"April\",\"5\":\"May\",\"6\":\"June\",\n",
    "         \"7\":\"July\", \"8\":\"August\", \"9\":\"September\",\"10\":\"October\",\"11\":\"November\", \"12\":\"December\"}\n",
    "\n",
    "    ord_days = {\"1st\":'first', \"2nd\":\"second\" , \"3rd\":'third', \"4th\":'fourth', \"5th\":'fifth', \"6th\":'sixth', \"7th\":'seventh', \"8th\":'eighth', \"9th\":'ninth', \"10th\":'tenth', \"11th\":'eleventh',\n",
    "    \"12th\":'twelfth', \"13th\":'thirteenth', \"14th\":'fourteenth', \"15th\":'fifteenth', \"16th\":'sixteenth', \"17th\":'seventeenth', \"18th\":'eighteenth', \"19th\":'nineteenth', \"20th\":'twentieth', \"21th\":'twenty-first',\n",
    "    \"22nd\":'twenty-second', \"23rd\":'twenty-third', \"24th\":'twenty-fourth', \"25th\":'twenty-fifth', \"26th\":'twenty-sixth', \"27th\":'twenty-seventh', \"28th\":'twenty-eighth', \"29th\":'twenty-ninth', \"30th\":'thirtieth', \"31st\":'thirty-first'}\n",
    "    x = re.sub(',','',x)\n",
    "    #Changing dates in form month/day/year\n",
    "    if len(x.split(\"/\")) == 3:\n",
    "        date = x.split(\"/\")\n",
    "        date[0] = month[date[0]]\n",
    "        date[1] = day[date[1]]\n",
    "        date[2] = year(date[2])\n",
    "        x_final = \" \".join(date).lower() \n",
    "    #Changing dates in form day.month.year\n",
    "    elif len(x.split(\".\")) == 3:\n",
    "        date = x.split(\".\")\n",
    "        date[1] = month[date[1]]\n",
    "        date[0] = day[date[0]]+\" of\"\n",
    "        date[2] = year(date[2])\n",
    "        x_final = \" \".join(date).lower() \n",
    "    # Dates written out\n",
    "    elif len(x.split(' ')) > 1:  #testing for words (well sentences) like days and numbers with units\n",
    "        date_list = x.split(' ')\n",
    "        for i,v in enumerate(date_list):\n",
    "            if v in ord_days:  #checking for date case 15th OF Jan.\n",
    "                if i == 0:\n",
    "                    date_list[i] = \"the \"+ord_days[v]+\" of\"\n",
    "                else:\n",
    "                    date_list[i] = ord_days[v]\n",
    "            if v.isdigit():\n",
    "                if i == 0 and len(v)<3:\n",
    "                    date_list[i] = \"the \"+day[v]+\" of\"\n",
    "                elif len(v)<3:\n",
    "                    date_list[i] = day[v]\n",
    "                elif len(v)==4:\n",
    "                    date_list[i] = year(v)\n",
    "            x_final = \" \".join(date_list)\n",
    "    elif len(x) == 4:\n",
    "        x_final = year(x)\n",
    "    else:\n",
    "        #in case we missed some (take a loss)\n",
    "        x_final = x\n",
    "        \n",
    "    x_final = re.sub(',',\"\",x_final)\n",
    "    x_final = re.sub('-',\" \",x_final)\n",
    "    return(x_final.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def money(x):\n",
    "    money = re.sub('([$£€])', r'\\1 ', x)\n",
    "    money = re.sub('\\s{2,}', ' ', money)\n",
    "    money = re.sub(r',', '', money)\n",
    "    money_list = money.split(' ')\n",
    "    if money_list[0] == '$':\n",
    "        money_list.append('dollars')\n",
    "        money_list = money_list[1:]\n",
    "    elif money_list[0] == '£':\n",
    "        money_list.append('pounds')\n",
    "        money_list = money_list[1:]\n",
    "    elif money_list[0] == '€':\n",
    "        money_list.append('euros')\n",
    "        money_list = money_list[1:]    \n",
    "    for i in range(len(money_list)):\n",
    "        if money_list[i].isdigit():\n",
    "            money_list[i] = num2words(int(money_list[i]))\n",
    "        elif is_float(money_list[i]):\n",
    "            money_list[i] = num2words(float(money_list[i]))\n",
    "            money_list[i] = re.sub(r' zero', '', money_list[i])\n",
    "    x = ' '.join(money_list)\n",
    "    x = re.sub(r',', '', x)\n",
    "    x = re.sub(r'-', ' ', x)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit(x): \n",
    "    try:\n",
    "        x = re.sub('[^0-9]', '',x)\n",
    "        result_string = ''\n",
    "        for i in x:\n",
    "            result_string = result_string + cardinal(i) + ' '\n",
    "        result_string = result_string.strip()\n",
    "        return result_string\n",
    "    except:\n",
    "        return(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def telephone(x):\n",
    "    try:\n",
    "        result_string = ''\n",
    "        for i in range(0,len(x)):\n",
    "            if re.match('[0-9]+', x[i]):\n",
    "                result_string = result_string + cardinal(x[i]) + ' '\n",
    "            else:\n",
    "                result_string = result_string + 'sil '\n",
    "        return result_string.strip()    \n",
    "    except:    \n",
    "        return(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraction(x):\n",
    "    try:\n",
    "        y = x.split('/')\n",
    "        result_string = ''\n",
    "        y[0] = cardinal(y[0])\n",
    "        y[1] = ordinal(y[1])\n",
    "        if y[1] == 4:\n",
    "            result_string = y[0] + ' quarters'\n",
    "        else:    \n",
    "            result_string = y[0] + ' ' + y[1] + 's'\n",
    "        return(result_string)\n",
    "    except:    \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal(x):\n",
    "    try:\n",
    "        result_string = ''\n",
    "        x = x.replace(',', '')\n",
    "        x = x.replace('[\\.]$', '')\n",
    "        if re.match('^[0-9]+$',x):\n",
    "            x = num2words(int(x), ordinal=True)\n",
    "            return(x.replace('-', ' '))\n",
    "        if re.match('.*V|X|I|L|D',x):\n",
    "            if re.match('.*th|st|nd|rd',x):\n",
    "                x = x[0:len(x)-2]\n",
    "                x = rom_to_int(x)\n",
    "                result_string = re.sub('-', ' ',  num2words(x, ordinal=True))\n",
    "            else:\n",
    "                x = rom_to_int(x)\n",
    "                result_string = 'the '+ re.sub('-', ' ',  num2words(x, ordinal=True))\n",
    "        else:\n",
    "            x = x[0:len(x)-2]\n",
    "            result_string = re.sub('-', ' ',  num2words(float(x), ordinal=True))\n",
    "        return(result_string)  \n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinal(x):\n",
    "    try:\n",
    "        if re.match('.*[A-Za-z]+.*', x):\n",
    "            return x\n",
    "        x = re.sub(',', '', x, count = 10)\n",
    "\n",
    "        if(re.match('.+\\..*', x)):\n",
    "            x = num2words(float(x))\n",
    "        elif re.match('\\..*', x): \n",
    "            x = num2words(float(x))\n",
    "            x = x.replace('zero ', '', 1)\n",
    "        else:\n",
    "            x = num2words(int(x))\n",
    "        x = x.replace('zero', 'o')    \n",
    "        x = re.sub('-', ' ', x, count=10)\n",
    "        x = re.sub(' and','',x, count = 10)\n",
    "        return x\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def address(x):\n",
    "    try:\n",
    "        x = re.sub('[^0-9a-zA-Z]+', '', x)\n",
    "        x_list = [char for char in x]\n",
    "        for i in range(len(x_list)):\n",
    "            if re.match('[A-Z]|[a-z]',x_list[i]):\n",
    "                x_list[i] = x_list[i].lower() \n",
    "            else:\n",
    "                continue\n",
    "        x = \"\".join(x_list)\n",
    "        x_list2 = x.split(' ')\n",
    "        for i in range(len(x_list2)):\n",
    "            if re.match('[0-9]',x_list2[i]):                        \n",
    "                x_list2[i]=(num2words(int(x_list2[i])))\n",
    "        x = \" \".join(x_list2)\n",
    "        return(x)\n",
    "    except:\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters(x):\n",
    "    try:\n",
    "        x = re.sub('[^a-zA-Z]', '', x)\n",
    "        x = x.lower()\n",
    "        result_string = ''\n",
    "        for i in range(len(x)):\n",
    "            result_string = result_string + x[i] + ' '\n",
    "        return(result_string.strip())  \n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def electronic(x):\n",
    "    try:\n",
    "        replacement = {'.' : 'dot', ':' : 'colon', '/':'slash', '-' : 'dash', '#' : 'hash tag', }\n",
    "        result_string = ''\n",
    "        if re.match('.*[A-Za-z].*', x):\n",
    "            for char in x:\n",
    "                if re.match('[A-Za-z]', char):\n",
    "                    result_string = result_string + letters(char) + ' '\n",
    "                elif char in replacement:\n",
    "                    result_string = result_string + replacement[char] + ' '\n",
    "                elif re.match('[0-9]', char):\n",
    "                    if char == 0:\n",
    "                        result_string = result_string + 'o '\n",
    "                    else:\n",
    "                        number = cardinal(char)\n",
    "                        for n in number:\n",
    "                            result_string = result_string + n + ' ' \n",
    "            return result_string.strip()                \n",
    "        else:\n",
    "            return(x)\n",
    "    except:    \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "from num2words import num2words\n",
    "import gc\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import code\n",
    "from io import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = r'C:/Users/CHICHI/Desktop/文本正则化/input'\n",
    "DATA_INPUT_PATH = r'C:/Users/CHICHI/Desktop/input/文本正则化/'\n",
    "SUBM_PATH = r'C:/Users/CHICHI/Desktop/文本正则化/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = str.maketrans(\"₀₁₂₃₄₅₆₇₈₉\", \"0123456789\")\n",
    "SUP = str.maketrans(\"⁰¹²³⁴⁵⁶⁷⁸⁹\", \"0123456789\")\n",
    "OTH = str.maketrans(\"፬\", \"4\")\n",
    "INCH_TMP = r'\\d+\"\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:4: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<ipython-input-39-db35e8c272d7>:4: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  data = [x for x in data if x is not '']\n"
     ]
    }
   ],
   "source": [
    "def inflect_transform(data):\n",
    "    data = re.sub(r'-|,|\\band\\b', ' ', data)\n",
    "    data = data.split(' ')\n",
    "    data = [x for x in data if x is not '']\n",
    "    return ' '.join(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WEB_transform(data):\n",
    "    if '.' not in data:\n",
    "        return data\n",
    "    before = data\n",
    "    after = []\n",
    "    m = {u'.':'dot', \n",
    "         u'/':'slash',\n",
    "         u':':'colon',\n",
    "         u',':'comma',\n",
    "         u'-':'dash'}\n",
    "    for char in data:\n",
    "        if char in m:\n",
    "            after.append(m[char])\n",
    "        else:\n",
    "            after.append(char)\n",
    "    after = ' '.join(after)\n",
    "    #print('before:', before)\n",
    "    #print('after:', after)\n",
    "    return ' '.join(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def INCH_transform(data):\n",
    "    neo_data = data[:-2]\n",
    "    return ' '.join([inflect_transform(num2words(int(neo_data))), 'inches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    print('Train start...')\n",
    "    \n",
    "    file = \"en_train.csv\"\n",
    "    train = open(os.path.join(INPUT_PATH, \"en_train.csv\"), encoding='UTF8')\n",
    "    line = train.readline()\n",
    "    #res = dict()\n",
    "    res_class = dict()\n",
    "    total = 0\n",
    "    not_same = 0\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        total += 1\n",
    "        pos = line.find('\",\"')\n",
    "        text = line[pos + 2:]\n",
    "        if text[:3] == '\",\"':\n",
    "            continue\n",
    "        text = text[1:-1]\n",
    "        arr = text.split('\",\"')\n",
    "        # arr[0], arr[1] are 'before', 'after' now\n",
    "        pos_class = line.find(',\"')\n",
    "        text_class = line[pos_class+2:pos]\n",
    "\n",
    "        if arr[0] != arr[1]:\n",
    "            not_same += 1\n",
    "        #if arr[0] not in res:\n",
    "        #    res[arr[0]] = dict()\n",
    "        #    res[arr[0]][arr[1]] = 1\n",
    "        #else:\n",
    "        #    if arr[1] in res[arr[0]]:\n",
    "        #        res[arr[0]][arr[1]] += 1\n",
    "        #    else:\n",
    "        #        res[arr[0]][arr[1]] = 1\n",
    "\n",
    "        if ('.'.join([arr[0], text_class])) not in res_class:\n",
    "            res_class['.'.join([arr[0], text_class])] = dict()\n",
    "            res_class['.'.join([arr[0], text_class])][arr[1]] = 1\n",
    "        else:\n",
    "            if arr[1] in res_class['.'.join([arr[0], text_class])]:\n",
    "                res_class['.'.join([arr[0], text_class])][arr[1]] += 1\n",
    "            else:\n",
    "                res_class['.'.join([arr[0], text_class])][arr[1]] = 1\n",
    "\n",
    "    train.close()\n",
    "    print(file + ':\\tTotal: {} Have diff value: {}'.format(total, not_same))\n",
    "    gc.collect()\n",
    "    #return res\n",
    "    return res_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_res(res, path):\n",
    "    with io.open(path, 'w', encoding='utf8') as f:\n",
    "        f.write(json.dumps(res, ensure_ascii=False, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_res(path):\n",
    "    with io.open(path) as f:\n",
    "        res = json.loads(f.read())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/CHICHI/Desktop/文本正则化/output/res_class.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-be919b4d4a18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mres_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/CHICHI/Desktop/文本正则化/output/res.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mres_class_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/CHICHI/Desktop/文本正则化/output/res_class.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mres_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_res\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_class_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_res\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-6ff5a652b87d>\u001b[0m in \u001b[0;36mload_res\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_res\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/CHICHI/Desktop/文本正则化/output/res_class.json'"
     ]
    }
   ],
   "source": [
    "res_path = 'C:/Users/CHICHI/Desktop/文本正则化/output/res.json'\n",
    "res_class_path = 'C:/Users/CHICHI/Desktop/文本正则化/output/res_class.json'\n",
    "res_class = load_res(res_class_path)\n",
    "res = load_res(res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-53882561d4e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'len(res): {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'len(res_class): {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "print('len(res): {}'.format(len(res)))\n",
    "print('len(res_class): {}'.format(len(res_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdict = {}\n",
    "sdict['km2'] = 'square kilometers'\n",
    "sdict['km'] = 'kilometers'\n",
    "sdict['kg'] = 'kilograms'\n",
    "sdict['lb'] = 'pounds'\n",
    "sdict['dr'] = 'doctor'\n",
    "sdict['m²'] = 'square meters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    total = 0\n",
    "    changes = 0\n",
    "\n",
    "    m = {}\n",
    "    \n",
    "    out = open(os.path.join(SUBM_PATH, 'baseline_ext_class_en.csv'), \"w\", encoding='UTF8')\n",
    "    out.write('\"id\",\"after\"\\n')\n",
    "    test = open(os.path.join(INPUT_PATH, \"en_test_2.csv\"), encoding='UTF8')\n",
    "    pred = open(os.path.join(SUBM_PATH, \"pred_test_2.csv\"), encoding='UTF8')\n",
    "    line = test.readline().strip()\n",
    "    line_pred = pred.readline().strip()\n",
    "    while 1:\n",
    "        line = test.readline().strip()\n",
    "        try:\n",
    "            line_pred = pred.readline().strip()\n",
    "        except:\n",
    "            code.interact(local=locals())\n",
    "        if line == '':\n",
    "            break\n",
    "    \n",
    "        pos = line.find(',')\n",
    "        i1 = line[:pos]\n",
    "        line = line[pos + 1:]\n",
    "    \n",
    "        pos = line.find(',')\n",
    "        i2 = line[:pos]\n",
    "        line = line[pos + 1:]\n",
    "    \n",
    "        line = line[1:-1]\n",
    "        out.write('\"' + i1 + '_' + i2 + '\",')\n",
    "\n",
    "        pos = line_pred.rfind(',')\n",
    "        tag = line_pred[pos + 1:]\n",
    "        label = tag\n",
    "\n",
    "        before = line\n",
    "\n",
    "        if \".\".join([line, tag]) in res_class:\n",
    "            srtd = sorted(res_class[\".\".join([line, tag])].items(), key=operator.itemgetter(1), reverse=True)\n",
    "            line = srtd[0][0]\n",
    "\n",
    "            line = re.sub(r'\\b_letter\\b', ' ', line)\n",
    "            for l in string.ascii_letters[:26]:\n",
    "                line = re.sub(l+'_letter', l, line)\n",
    "            line = ' '.join(filter(lambda x: x, line.split(' ')))\n",
    "            #if before != line:\n",
    "            #    print('before:', before)\n",
    "            #    print('after:', line) \n",
    "\n",
    "            out.write('\"' + line + '\"')\n",
    "            m[\".\".join([before, tag])] = line \n",
    "            changes += 1\n",
    "        elif line in res:\n",
    "            #if len(res[line]) > 1:\n",
    "            #    m[line] = [total, res[line]]\n",
    "            if tag == 'ELECTRONIC' and '.' in line:\n",
    "                line = WEB_transform(line)\n",
    "            else:\n",
    "                # here return the first (value, cnt) with line as key\n",
    "                srtd = sorted(res[line].items(), key=operator.itemgetter(1), reverse=True)\n",
    "                line = srtd[0][0]\n",
    "\n",
    "                before = line\n",
    "                line = re.sub(r'\\b_letter\\b', ' ', line)\n",
    "                for l in string.ascii_letters[:26]:\n",
    "                    line = re.sub(l+'_letter', l, line)\n",
    "                line = ' '.join(filter(lambda x: x, line.split(' ')))\n",
    "                #if before != line:\n",
    "                #    print('before:', before)\n",
    "                #    print('after:', line) \n",
    "\n",
    "            out.write('\"' + line + '\"')\n",
    "            changes += 1\n",
    "\n",
    "        elif label == 'ADDRESS':\n",
    "            try:\n",
    "                norm = address(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'CARDINAL'\n",
    "        elif label == 'CARDINAL':\n",
    "            try:\n",
    "                norm = cardinal(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'DATE'\n",
    "        elif label == 'DATE':\n",
    "            try:\n",
    "                norm = date(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'DECIMAL'\n",
    "        elif label == 'DECIMAL':\n",
    "            try:\n",
    "                norm = decimal(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'DIGIT',\n",
    "        elif label == 'DIGIT':\n",
    "            try:\n",
    "                norm = digit(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'ELECTRONIC',\n",
    "        elif label == 'ELECTRONIC':\n",
    "            try:\n",
    "                norm = electronic(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'FRACTION',\n",
    "        elif label == 'FRACTION':\n",
    "            try:\n",
    "                norm = fraction(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'LETTERS',\n",
    "        elif label == 'LETTERS':\n",
    "            try:\n",
    "                norm = letters(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'MEASURE',\n",
    "        elif label == 'MEASURE':\n",
    "            try:\n",
    "                norm = measure(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'MONEY',\n",
    "        elif label == 'MONEY':\n",
    "            try:\n",
    "                norm = money(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'ORDINAL',\n",
    "        elif label == 'ORDINAL':\n",
    "            try:\n",
    "                norm = ordinal(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'PLAIN' nothing changes\n",
    "        elif label == 'PLAIN':\n",
    "            norm = before\n",
    "            out.write('\"' + norm + '\"')\n",
    "        #'PUNCT',\n",
    "        elif label == 'PUNCT':\n",
    "            norm = before\n",
    "            out.write('\"' + norm + '\"')\n",
    "        #'TELEPHONE',\n",
    "        elif label == 'TELEPHONE':\n",
    "            try:\n",
    "                norm = telephone(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'TIME',\n",
    "        elif label == 'TIME':\n",
    "            try:\n",
    "                norm = time(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "        #'VERBATIM'\n",
    "        elif label == 'VERBATIM':\n",
    "            try:\n",
    "                norm = verbatim(before)\n",
    "                out.write('\"' + norm + '\"')\n",
    "                changes += 1\n",
    "            except:\n",
    "                out.write('\"' + line + '\"')\n",
    "\n",
    "        else:\n",
    "            print(line)\n",
    "            # actually there are only four inches not appeared\n",
    "            \n",
    "            if len(line) > 1:\n",
    "                val = line.split(',')\n",
    "                # number with at most 1 ','\n",
    "                if len(val) == 2 and val[0].isdigit() and val[1].isdigit():\n",
    "                    line = ''.join(val)\n",
    "    \n",
    "            if line.isdigit():\n",
    "                srtd = line.translate(SUB)\n",
    "                srtd = srtd.translate(SUP)\n",
    "                srtd = srtd.translate(OTH)\n",
    "                out.write('\"' + num2words(float(srtd)) + '\"')\n",
    "                changes += 1\n",
    "            elif len(line.split(' ')) > 1:\n",
    "                val = line.split(' ')\n",
    "                for i, v in enumerate(val):\n",
    "                    if v.isdigit():\n",
    "                        srtd = v.translate(SUB)\n",
    "                        srtd = srtd.translate(SUP)\n",
    "                        srtd = srtd.translate(OTH)\n",
    "                        val[i] = num2words(float(srtd))\n",
    "                    # measure\n",
    "                    elif v in sdict:\n",
    "                        val[i] = sdict[v]\n",
    "    \n",
    "                out.write('\"' + ' '.join(val) + '\"')\n",
    "                changes += 1\n",
    "            elif re.match(INCH_TMP, line):\n",
    "                line = INCH_transform(line)\n",
    "                print(line)\n",
    "                out.write('\"' + line + '\"')\n",
    "                changes += 1\n",
    "            else:\n",
    "                out.write('\"' + line + '\"')\n",
    "    \n",
    "        out.write('\\n')\n",
    "        total += 1\n",
    "    \n",
    "    print('Total: {} Changed: {}'.format(total, changes))\n",
    "    test.close()\n",
    "    out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/CHICHI/Desktop/文本正则化/output/ambi_class.json', 'w', encoding='utf8') as f:\n",
    "    f.write(json.dumps(m, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
